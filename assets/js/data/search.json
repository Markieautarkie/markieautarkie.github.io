[ { "title": "Building a Ray Tracer - Part 4: Powerful Polymorphism", "url": "/posts/building-a-ray-tracer-part-4-powerful-polymorphism/", "categories": "Projects, Manta Ray", "tags": "c++, ray tracing, intersections, abstraction", "date": "2022-07-30 13:36:27 +0200", "snippet": "This post is going to tie up the loose ends we left dangling around in the previous post. We put quite some effort into abstracting the setup for intersectable primitives, yet we still have to deal with conditionals for each individual object added to the scene. Plus, due to the way we execute these conditionals, we don’t take into account whether the intersection we found is the closest one or not.Let’s fix these issues by creating another layer of abstraction. Each of the implemented primitives so far inherits from the abstract intersectable class, which describes a generic object that a ray can interact with. We can abuse this property by introducing a list of intersectables, which in turn also inherits from the intersectable class! This allows us to store any object which inherits from the abstract base class in the list, no matter if it is a sphere, triangle, plane, or whatever. Now we could loop over this list and let C++ figure out what kind of object we are dealing with on its own; it will automagically grab the correct intersect method! This neat feature is called polymorphism, an absolute staple of object-oriented programming languages.Creating a list of intersectable objectsWe’ll jot down the class definition first. The intersectable_list class holds one single variable; the list of intersectable objects. We will use two c++ specfic features to create this variable: vector: this is a generic collection type, comparable to an array. It can store any arbitrary type, but in our case it will store objects of class type intersectable. A nice feature of the vector collection is that it automatically grows (and shrinks) to fit objects we add or remove. shared_ptr: this is a special type of pointer, which has reference-counting properties (unlike normal C++ pointers). Long story short, it helps us with memory management and it can even make the application more efficient in some cases. These features are introduced to deal with the manual pointer management present in C++. In most other object-oriented languages you don’t need to worry about this; a normal list structure will often suffice!Without further ado, here’s the implementation:#pragma onceclass intersectable_list : public intersectable{private: vector&lt;shared_ptr&lt;intersectable&gt;&gt; m_objects;public: intersectable_list() {} intersectable_list(shared_ptr&lt;intersectable&gt; object) { add(object); } // methods to add/remove objects from the list void add(shared_ptr&lt;intersectable&gt; object) { m_objects.push_back(object); } void clear() { m_objects.clear(); } virtual bool intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const override;};Now for the intersect method. Since we’re dealing with a container for intersectable primitives/objects, the implementation will deal with looping over each object in the list. By taking into account the current closest found value for $t$, we can guarantee that the function will always return the closest intersection. The implementation is as follows:#include \"precomp.h\"bool intersectable_list::intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const{ // initially no intersection has taken place yet, // and set the closest intersection boundary to the provided maximum bool intersected = false; float t_closest = t_max; // temporary intersection data, will update whenever a closer intersection is found intersect_data temp_data; // loop over each object in the intersectable_list and check if the ray intersects with it for (const shared_ptr&lt;intersectable&gt;&amp; object : m_objects) if (object-&gt;intersect(r, temp_data, t_min, t_closest)) { // an intersection was found, // the closest value for t is the current intersection, // store the current intersection data intersected = true; t_closest = temp_data.t; data = temp_data; } // returns true if the ray intersected anything at all // if so, \"data\" will hold the information about the closest intersection return intersected;}Perfect! The only thing left to do is update the mantaray.cpp file. Now we only have to instance whatever primitives we want, and the intersectable_list will take care of the rest:intersectable_list scene;// anything that happens only once at application start goes herevoid mantaray::Init(){ // add a plane, sphere and a triangle with some parameters to the scene scene.add(make_shared&lt;plane&gt;(float3(0.0f, -1.0f, 0.0f), 1.0f)); scene.add(make_shared&lt;sphere&gt;(float3(0.0f, 0.0f, 1.0f), 0.25f)); scene.add(make_shared&lt;triangle&gt;( float3(-0.25f, 0.1f, 0.5f), float3(0.0f, 2.5f, 5.0f), float3(0.25f, -0.2f, 0.5f)));}color ray_color(const ray&amp; r){ // check for each ray whether it intersects with an object in the scene intersect_data data; if (scene.intersect(r, data, 0.0f, LARGE_FLOAT)) // if an intersection is found, return a color based on the normal at that intersection return 0.5f * (data.normal + color(1.0f)); // if there is no intersection, render the background as usual // background code here...}Running the application now gives the following result:A scene containing all the object types we’ve added so far. It only renders the closest intersection point (hence the clipping).And with that, we finished up the abstractions for now! The next post will be the most exciting chapter yet, as we will implement Whitted-style ray tracing. All the hard work we did will finally pay off, so I hope you are looking forward to it!" }, { "title": "Building a Ray Tracer - Part 3: Intersection Galore!", "url": "/posts/building-a-ray-tracer-part-3-intersection-galore/", "categories": "Projects, Manta Ray", "tags": "c++, ray tracing, vectors, intersections, abstraction", "date": "2022-07-30 00:12:20 +0200", "snippet": "Last time we left off with a (pretty empty) backdrop for the ray tracing scene. With ray functionality and a basic camera implemented, our focus shifts to actually rendering some primitives. And to do that, we need to talk about intersections. Also math. Lots, and lots of math… But it will be fun, I promise!Rather planeLet’s kick things off with the implementation of an infinite plane, as it is simple to construct. One of the many ways to express an infinite plane is defined by the following function:\\[P \\cdot \\overrightarrow{N} + d = 0\\]Where $P$ is a point in 3D space, $\\overrightarrow{N}$ the normal vector of the plane and $d$ a scalar offset.You might be wondering what a “normal vector” is at this point; in short, it is a vector whose direction is perpendicular to a certain surface - in this case, the surface of a plane. Normals are used absolutely everywhere in graphical applications. For now this quick introduction will suffice though. Note that a normal vector and the act of “normalizing” a vector (ensuring that the length of a vector is equal to 1) are two very different concepts!Perhaps you recall from the last post that the ray equation is defined as $P(t) = O + t\\overrightarrow{D}$, giving us a point in 3D space along the ray. Due to one of the many cool properties of mathematics, we can substitute for $P$ in the plane equation by plugging in the ray formula:\\[(O + t\\overrightarrow{D}) \\cdot \\overrightarrow{N} + d = 0\\]To figure out whether a ray intersects with the plane, we need to find a value for $t$ which satisfies this formula. In other words, by isolating $t$ in the equation we’ll find exactly what we’re looking for:\\[\\rightarrow O \\cdot \\overrightarrow{N} + t\\overrightarrow{D} \\cdot \\overrightarrow{N} + d = 0\\]\\[\\rightarrow t\\overrightarrow{D} \\cdot \\overrightarrow{N} = -(O \\cdot \\overrightarrow{N} + d)\\]\\[\\rightarrow t = -(O \\cdot \\overrightarrow{N} + d) / (\\overrightarrow{D} \\cdot \\overrightarrow{N})\\]Great! Let’s translate this final equation into code:// returns \"true\" if the ray intersects the plane, false otherwisebool intersect_plane(const ray&amp; r, const float3&amp; normal, float offset){ // D . N -&gt; to avoid division by zero, // if the calculated value is close to zero return false float denominator = dot(r.direction(), normal); if (abs(denominator) &lt; 0.00001f) return false; // O . N + d float numerator = dot(r.origin(), normal) + offset; // -(O . N + d) / (D . N) float t = -numerator / denominator; // if t is zero or positive, the ray intersects the plane return t &gt;= 0.0f;}Now to expand the ray_color function just a tad in order to check for an arbitrary plane in the scene:color ray_color(const ray&amp; r){ // check if the current ray intersects a plane with its normal pointing upwards, // and the plane offset slightly down from the camera if (intersect_plane(r, float3(0.0f, -1.0f, 0.0f), 1.0f)) // return green as a color when there is an intersection return color(0.0f, 1.0f, 0.0f); // if there is no intersection, render the background as usual // background code here...}Running the application now gives us an infinite plane rendered all the way towards the horizon (a grassy field, if you will). And with that… The first intersection implementation is finished!Mr. Blue Sky, meet Mr. Green Field.AbstractionSweet, we implemented a way to intersect a ray with a plane. But what if we want to check several planes? Do we need to describe a specific condition for each of them? What happens when we also want to add spheres or triangles as intersectable primitives? If we carry on like this, we’ll end up with an unmanageable mess of spaghetti code which would be hard to maintain in the future…Luckily, many object-oriented programming languages such as C++ have built-in features to add layers of abstraction. If we think about it, we don’t really care about what a ray intersects with; there should just be function defined for each primitive which handles that intersection for us. As such, each of the primitives/objects we implement needs some kind of intersection method. Furthermore, we should track a set of variables that describes the intersection, like the intersection point, the normal vector at that intersection and the value for $t$ at that intersection. Time to cram all this stuff in an abstract, intersectable class:#pragma once// this struct holds the data which is saved when a ray intersection happensstruct intersect_data{ float t; float3 point; float3 normal;};// an abstract class which describes primitives/objects which can be intersectedclass intersectable{public: virtual bool intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const = 0;}; The abstract intersect method also takes two scalar values, t_min and t_max. These will be used to define an interval for which the intersection is valid. This will be useful in the future!How do you like your normals?There’s a small design decision to make regarding normal vectors. A normal can point outwards or inwards, depending how you look at the surface. For example, how do we handle a normal when we look at the backside of a plane?As of now, the normal always points outwards from the surface. Another possibility is to always point the normal vector against the ray direction. In this case the normal will point outwards when we are in front of a surface, and inwards when we are on the backside of a surface.Eventually we want to know which side of the surface we’re facing to apply the rendering in a correct manner. For this application I have chosen to always point the normal against the incident ray, as this allows us to save the information together with the intersection data.We’ll add a boolean to the intersection data which indicates whether the current intersection is from the front or the back of the surface, in turn flipping the normal accordingly via a function:// this struct holds the data which is saved when a ray intersection happensstruct intersect_data{ float t; float3 point; float3 normal; // check whether we are currently in front or behind/inside of the object, // flipping the normal accordingly bool front; inline void set_front(const ray&amp; r, const float3&amp; outward_normal) { // the dot product is negative if the ray direction and normal have opposite directions front = dot(r.direction(), outward_normal) &lt; 0.0f; // possibly flip the normal direction if we are behind/inside the object normal = normalize(front ? outward_normal : -outward_normal); }};Re-implementing infinite planesWith the abstract class in place for primitive/object intersection, we can rewrite our infinite plane implementation. First, I defined a new constant which denotes a very small floating point number. This will be useful in a lot of situations:#define EPSILON 0.00001fI also added an additional function which checks whether a value lies between two other values or not:inline bool between(float f, float a, float b) { return clamp(f, a, b) == f; }The new plane class inherits from the abstract intersectable class as follows:#pragma onceclass plane : public intersectable{private: float3 m_normal; float m_offset;public: plane() {} plane(float3 normal, float offset) : m_normal(normalize(normal)), m_offset(offset) {} virtual bool intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const override;};It holds a normal and an offset needed to define a plane. It has a more specific implementation of the intersect method as well; the code is basically the same as before, with some minor edits to save/update the intersection data:#include \"precomp.h\"bool plane::intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const{ // D . N -&gt; to avoid division by zero, // if the calculated value is close to 0 (ray parallel with plane) return false float denominator = dot(r.direction(), m_normal); if (abs(denominator) &lt; EPSILON) return false; // O . N + d // -(O . N + d) / (D . N) float numerator = dot(r.origin(), m_normal) + m_offset; float t = -numerator / denominator; // reject t if the value doesn't lie between the given boundaries if (!between(t, t_min, t_max)) return false; // update the intersection data data.t = t; data.point = r.point(t); data.set_front(r, m_normal); // the ray intersected with the plane return true;}Now that’s all out of the way, we can update mantaray.cpp to use the plane object and the underlying intersect method instead:plane p;// anything that happens only once at application start goes herevoid mantaray::Init(){ p = plane(float3(0.0f, -1.0f, 0.0f), 1.0f);}// returns a background gradient depending on the y direction of a primary raycolor ray_color(const ray&amp; r){ // check for a ray/plane intersection, return green if they intersect intersect_data temp_data; if (p.intersect(r, temp_data, 0.0f, LARGE_FLOAT)) return color(0.0f, 1.0f, 0.0f); // if there is no intersection, render the background as usual // background code here...}Running the application now produces the same result as before, but on the back-end things have been tidied up and are ready for expansion!Gettin’ sphericalSo let’s expand! Next on the list of primitives to implement is a good ol’ sphere. Once again it will inherit from the abstract intersectable class.Instead of a normal and an offset, a sphere is defined by its center position and a radius. Aside from that, the class implementation is pretty much identical to that of the infinite plane:#pragma onceclass sphere : public intersectable{private: float3 m_center; float m_radius;public: sphere() {} sphere(float3 center, float radius) : m_center(center), m_radius(radius) {} virtual bool intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const override;};Implementing the sphere intersect methodNow for the special version of the ray/sphere intersect function. Lo and behold, there exists an equation to describe a sphere with a radius $r$ centered at the origin:\\[P^2 = r^2\\]This states that any point $P$ is on the sphere’s surface if the equation holds. The point is inside the sphere if $P^2 \\lt r^2$ and the point is outside the sphere if $P^2 \\gt r^2$.However, the sphere isn’t necessarily located at the origin but at any point $C$, so we need to update the formula a bit:\\[(P - C)^2 = r^2\\]Which is equal to (dot product rule):\\[(P - C) \\cdot (P - C) = r^2\\]Once again we can substitute P for the ray equation $P(t) = O + t\\overrightarrow{D}$, leaving us with this:\\[(O + t\\overrightarrow{D} - C) \\cdot (O + t\\overrightarrow{D} - C) = r^2\\]Time to further expand this equation and solve it with the magic that is vector algebra. I will spare you the details, but eventually we end up with this quadratic formula:\\[\\overrightarrow{D} \\cdot \\overrightarrow{D}t^2 + 2\\overrightarrow{D} \\cdot (O - C)t + (O - C)^2 - r^2 = 0\\]If you weren’t vast asleep during math class at high school, you probably ran into the abc-formula before which we can use to solve quadratic functions:\\[t = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\]Simply plugging in the abc terms using the quadratic function we found gives:\\[a = \\overrightarrow{D} \\cdot \\overrightarrow{D}\\]\\[b = 2\\overrightarrow{D} \\cdot (O - C)\\]\\[c = (O - C)^2 - r^2\\]Now we can solve the formula to find a value for $t$. It can have 0, 1 or 2 solutions depending on the value below the square root (called the discriminant): If the discriminant is negative there are no solutions → the ray misses the sphere; If the discriminant is zero there is one solution → the ray shaves along the surface of the sphere, hitting it in exactly one point; If the discriminant is positive there are two solutions → the ray goes fully through the sphere and hits its surface while entering and exiting the sphere.Optimizing the yet-to-be-implemented sphere intersection methodAlthough we can already implement the intersect method as it stands, there are some easy optimizations we can do to simplify and speed up the calculations.First off, notice how the $b$ term we got from our quadratic function has a factor of 2 in it. We can use this to our advantage by simplifying the abc-formula even further when we consider $b = 2h$:\\[\\frac{-2h \\pm \\sqrt{(2h)^2 - 4ac}}{2a}\\]\\[\\rightarrow \\frac{-2h \\pm 2\\sqrt{h^2 - ac}}{2a}\\]\\[\\rightarrow \\frac{-h \\pm \\sqrt{h^2 - ac}}{a}\\]The $b$ term now changes to $h = \\overrightarrow{D} \\cdot (O - C)$.Next, consider that a the dot product of a vector with itself is equal to the squared length of that vector. We got an $a$ term which states $a = \\overrightarrow{D} \\cdot \\overrightarrow{D}$, so we can rewrite this part as $a = ||\\overrightarrow{D}||^2$. But wait… In the project, we ensured that the directional vector of a ray is always normalized! This means that its length will always be exactly 1, no matter in which direction it points:\\[a = 1^2 \\rightarrow a = 1\\]Awesome! The $a$ term is now a simple constant, so there’s no need to calculate it. In fact… We don’t need it anymore at all:\\[\\frac{-h \\pm \\sqrt{h^2 - 1c}}{1}\\]\\[\\rightarrow -h \\pm \\sqrt{h^2 - c}\\]Okay… I think this is as fancy as we can get for now, let’s get it implemented (finally!):#include \"precomp.h\"bool sphere::intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const{ // O - C // D . (O - C) // (O - C)^2 - r^2 float3 oc = r.origin() - m_center; float h = dot(r.direction(), oc); float c = sqrLength(oc) - m_radius * m_radius; // h^2 - c float discriminant = h * h - c; // if the discriminant is negative, there was no ray/sphere intersection // calculate the square root afterwards if (discriminant &lt; 0.0f) return false; float sqrt_discriminant = sqrt(discriminant); // abc-formula, try shortest distance solution first // if both solutions fall outside the given boundaries, reject the intersection float t = -h - sqrt_discriminant; if (!between(t, t_min, t_max)) { t = -h + sqrt_discriminant; if (!between(t, t_min, t_max)) return false; } // update the intersection data // the normal of the sphere is the vector between the intersection, // and the sphere's center data.t = t; data.point = r.point(t); data.set_front(r, data.point - m_center); // the ray intersected with the sphere return true;}Initializing a new sphere object in mantaray.cpp gives the following result:What about a red sun to complement the scene?Triangle timeOne more primitive should do it for now! And it might be the most important one, as pretty much everything in graphical applications consists out of the darn things. Once again we inherit from the intersectable class.A triangle is defined by 3 vertices (3D points that define the corners of the triangle) and we’ll add a centroid as well, which is the point in the very center of the triangle:#pragma onceclass triangle : public intersectable{private: float3 m_v0, m_v1, m_v2; float3 m_centroid;public: triangle() {} triangle(float3 v0, float3 v1, float3 v2) : m_v0(v0), m_v1(v1), m_v2(v2), m_centroid((v0 + v1 + v2) / 3.0f) {} virtual bool intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const override;};As for the triangle specific intersection method, I uh… “borrowed” it from Mr. Möller and Mr. Trumbore; the Möller-Trumbore intersection algorithm. There’s no reason to re-invent the wheel when bright minds already figured out a fast solution, so let’s just use that algorithm and get this show on the road:#include \"precomp.h\"bool triangle::intersect(const ray&amp; r, intersect_data&amp; data, float t_min, float t_max) const{ float3 edge1 = m_v1 - m_v0; float3 edge2 = m_v2 - m_v0; float3 h = cross(r.direction(), edge2); // calculate 'a' first, if it's almost 0 (ray parallel with triangle), return false float a = dot(edge1, h); if (between(a, -EPSILON, EPSILON)) return false; float f = 1.0f / a; float3 s = r.origin() - m_v0; float u = f * dot(s, h); if (!between(u, 0.0f, 1.0f)) return false; float3 q = cross(s, edge1); float v = f * dot(r.direction(), q); if (v &lt; 0.0f || u + v &gt; 1.0f) return false; float t = f * dot(edge2, q); if (t &lt; EPSILON) return false; // reject t if the value doesn't lie between the given boundaries if (!between(t, t_min, t_max)) return false; // update the intersection data data.t = t; data.point = r.point(t); data.set_front(r, cross(edge1, edge2)); // the ray intersected with the triangle return true;}Popping a triangle object in the scene gives us the final result for this post:I’m all out of witty remarks. Random blue triangle, that’s about it!Well, I’m supposed to be writing a post, not a book. 📚I should probably cut it off riiiiight about here for now. Next time we will add another layer of abstraction by creating a list of intersectable objects, before diving into pretty ray tracing stuff for realsies.Congratulations on making it through this math explosion, see ya next time!" }, { "title": "Building a Ray Tracer - Part 2: Vectors, Rays and Cameras", "url": "/posts/building-a-ray-tracer-part-2-vectors-rays-and-cameras/", "categories": "Projects, Manta Ray", "tags": "c++, ray tracing, vectors", "date": "2022-07-11 21:04:07 +0200", "snippet": "The previous post introduced the ray tracing project Manta Ray, which we put in motion by writing an image to the screen buffer of the renderer. Next, we’re going to take a look at vectors, rays and a simple camera system for the renderer.VectorsAt the heart of ray tracers (or almost any graphical program for that matter) lay vectors. As you might already know, a vector is a quantity that has a magnitude and a direction, commonly represented by a line segment. We’ll be using vectors to denote many types of data within the program such as directions, locations, offsets and even colors.Luckily, the base template we’re using has already implemented vector constructions and accompanying mathematics for us. Since we work in 3D space, the predefined float3 struct is just what we need; it stores x, y and z coordinate components with floating point precision and it has all the vector functions we’d need for now. Going forward, I will assume that you have a basic understanding of vector related mathematics! New to vectors or do you need a refresher? This video is a great recap of everything you’d need to know about vector math!Color simplificationAt the moment we pass the screen-&gt;Plot function a uint for a color. Shifting bits around whenever we need to work with colors isn’t very intuitive, so let’s practice what we preach and use float3 to represent colors instead.First, we define a color alias for float3:// type alias for float3, defined below its existing struct implementationusing color = float3;Let’s create a utility function that helps us convert a color back to a uint:#pragma onceinline uint convert_color(const color&amp; pixel_color){ // convert the calculated values from a [0, 1] range to a [0, 255] RGB range, // then shift the bits to combine the colors in one unsigned integer return (static_cast&lt;int&gt;(255.0f * pixel_color.x) &lt;&lt; 16) + (static_cast&lt;int&gt;(255.0f * pixel_color.y) &lt;&lt; 8) + (static_cast&lt;int&gt;(255.0f * pixel_color.z));}Now we can reflect these changes in our main source file:// this method is called once per frame while the application is runningvoid mantaray::Tick(float deltaTime){ // clear the previously drawn frame by resetting the screen buffer to black screen-&gt;Clear(0); // loop over all the screen buffer pixels as if reading a book: left-&gt;right, top-&gt;bottom for (int y = 0; y &lt; SCRHEIGHT; y++) for (int x = 0; x &lt; SCRWIDTH; x++) { // calculate some values for the red, green and blue components of a pixel color pixel_color(float(x) / (SCRWIDTH - 1), 0.25f, float(y) / (SCRHEIGHT - 1)); // draw the color to the current screen buffer pixel screen-&gt;Plot(x, y, convert_color(pixel_color)); }}Ray tracing in a nutshellIn the previous post I mentioned that ray tracers try to simulate real-life physics. The image below gives an overview of a typical ray tracing scene:A simplified overview of a typical ray tracing scenario.Here we see a camera (depicted as an eye) shooting rays into the scene through a virtual viewport (the black line). This is the core concept of ray tracing: sending rays through pixels, then computing the color seen along those rays to render an image. We can dissect this process into the following steps: Ray calculation: calculate the rays from the camera to every pixel on the virtual viewport (the red arrows). These rays are also called primary rays. Ray intersection: calculate the nearest intersection point between each ray and any object in the scene, if it exists. Only the nearest intersection is important; any intersection further along the ray is obstructed by the first one anyway! Ray color: compute a color for the found intersection points, summing up the contribution of any light sources visible from each point. This is achieved by so-called shadow rays (the yellow dashed lines).For now, let’s solely focus on the first step. To calculate rays spawning from the camera, we’d need to (obviously) put both in the code somehow, which will be our next focus point. You might have noticed that ray tracing handles light transport backwards; that is, from camera to light source. This gives the renderer a performance boost as we only care about the rays that’ll actually hit the camera.Implementing raysAll ray tracers have some implementation in place to compute ray-specific values in order to render an image (I know, total shocker right?). A ray can be defined as an infinite half-line; basically a line in 3D space with a starting point. This leads to the following function:\\[P(t) = O + t\\overrightarrow{D}\\]Where $O$ is the ray origin and $\\overrightarrow{D}$ the (normalized) direction of the ray. Any 3D point $P$ along the ray can be found by plugging in values for $t$, where $t \\geq 0$. In other words, different values for $t$ moves point $P$ along the ray. This will be useful to find the exact intersection points of a ray with objects in a scene.Let’s add a ray class to the project which implements this functionality:#pragma onceclass ray{private: float3 m_origin; float3 m_direction;public: // constructors, ray direction is normalized ray() {} ray(const float3&amp; origin, const float3&amp; direction) : m_origin(origin), m_direction(normalize(direction)) {} // getters float3 origin() const { return m_origin; } float3 direction() const { return m_direction; } // gets the position for the given t value float3 point(float t) const { return m_origin + t * m_direction; }}; Normalizing the ray direction isn’t strictly necessary at this stage. However, forgetting to normalize when it does matter can lead to strange bugs. Be wary of this if you choose to omit it for now!Implementing a cameraNext, the camera. The camera consist of a position and a virtual viewport; the viewport is comparable to a lens in a real camera.To start, let’s define an aspect ratio for the screen buffer of the renderer (16:9 is a common standard), which we can use to set the screen resolution as well:constexpr float m_aspect = 16.0f / 9.0f;constexpr int m_scr_width = 640;constexpr int m_scr_height = m_scr_width / m_aspect;#define ASPECT m_aspect#define SCRWIDTH m_scr_width#define SCRHEIGHT m_scr_heightFor the viewport we will use the same aspect ratio to ensure the pixels are perfect squares. We could always change this later to get cool effects such as barrel- or pincushion distortion… Kinda like changing lenses on a camera!The viewport will be two units in height, as will be the distance between the camera origin and the viewport (the focal length of a camera). To keep things simple, let’s put the camera origin at $(0, 0, 0)$. Recall from the previous post that the coordinate system in graphics applications starts in the top-left corner, where x and y are positive when going to the right and down respectively. Hence why I have chosen to do the same for the camera coordinate system, making the program less confusing. To respect the right handed coordinate system, the z-axis will be positive going into the screen; or differently phrased, the value of z will be larger when the depth is greater.An overview of the camera and viewport geometry.The last thing we need to set up is a way to position a ray relative to the viewport. By traversing the screen from the top-left corner, we can reach any pixel on the viewport by “walking” a certain distance along the horizontal and vertical axis vectors of the viewport. We denote this distance as $u$ for the horizontal axis, and $v$ for the vertical one. This gives the following formula for any point on the virtual viewport:\\[P(u, v) = P_{topleft} + u\\overrightarrow{D}_{hor} + v\\overrightarrow{D}_{vert}\\]Where $u, v \\in [0, 1]$. Thus, $u$ and $v$ determine the ratio, where $(u, v = 0)$ is the top-left corner, and $(u, v = 1)$ the bottom-right one (similar to the color rendering in the previous post!).Now that we finally have a position on the virtual viewport, we can construct a ray from the camera through this position by subtracting the camera origin:\\[\\overrightarrow{D}_{ray} = P(u, v) - P_{origin}\\]Pfew, time to translate this all to code:#pragma onceclass camera{private: float3 m_origin; float3 m_horizontal; float3 m_vertical; float3 m_focal; float3 m_upper_left_corner;public: camera() { // initialize the viewport dimensions float viewport_height = 2.0f; float viewport_width = ASPECT * viewport_height; float focal_length = 2.0f; // create the viewport by defining the horizontal/vertical/focal vectors // and set the camera origin at (0.0f,0.0f,0.0f) m_origin = float3(0.0f); m_horizontal = float3(viewport_width, 0.0f, 0.0f); m_vertical = float3(0.0f, viewport_height, 0.0f); m_focal = float3(0.0f, 0.0f, focal_length); // calculate the position of the upper left corner of the virtual viewplane, // using the created vectors/positions m_upper_left_corner = m_origin - m_horizontal / 2.0f - m_vertical / 2.0f + m_focal; } // fire a new ray from the camera, with u and v defining the ratio to the viewport ray fire_ray(float u, float v) const { return ray(m_origin, m_upper_left_corner + u * m_horizontal + v * m_vertical - m_origin); }};To test the new camera, I implemented a simple temporary function which returns a color for a ray depending on its y direction called ray_color. All these changes are reflected in the main source file as follows:camera cam;// returns a background gradient depending on the y direction of a primary raycolor ray_color(const ray&amp; r){ // convert a ray's y value from roughly [-0.5, 0.5] space (due to vector normalization) to [0, 1] space float t = r.direction().y + 0.5f; // linear interpolation of the background, t = 0 gives blue-ish, t = 1 gives white, blend in-between return lerp(color(0.5f, 0.7f, 1.0f), color(1.0f), t);}// this method is called once per frame while the application is runningvoid mantaray::Tick(float deltaTime){ // clear the previously drawn frame by resetting the screen buffer to black screen-&gt;Clear(0); // loop over all the screen buffer pixels as if reading a book: left-&gt;right, top-&gt;bottom for (int y = 0; y &lt; SCRHEIGHT; y++) for (int x = 0; x &lt; SCRWIDTH; x++) { // calculate the u and v value for the current pixel and fire a ray using these values float u = float(x) / (SCRWIDTH - 1); float v = float(y) / (SCRHEIGHT - 1); color pixel_color = ray_color(cam.fire_ray(u, v)); // draw the color to the current screen buffer pixel screen-&gt;Plot(x, y, convert_color(pixel_color)); }}Behold! Our first “ray traced” image:Mr. Blue Sky, please tell us why, you had to hide away for so long (so long)!It’s… Rather dull for the amount of effort. However! We made some major strides coming to this point. The backbone of our renderer is now (mostly) in place. Next time we will implement step 2 of the rendering process: ray intersection! See ya later. 🐊" }, { "title": "Building a Ray Tracer - Part 1: Hello Manta Ray!", "url": "/posts/building-a-ray-tracer-part-1-hello-manta-ray/", "categories": "Projects, Manta Ray", "tags": "c++, ray tracing, introduction", "date": "2022-07-02 12:30:07 +0200", "snippet": "IntroductionMany a year ago, my brother got a brand new Nintendo 64 for his birthday. I still fondly remember the first time he flicked it on; seeing that floating Mario head pop up on the CRT in its full 3D glory blew my little mind away. I couldn’t phantom that graphics would ever get more lifelike… Or so I thought!At the time, Super Mario 64 was both impressive due to the fantastic gameplay (but that’s a topic for another day!) as for its visuals. Especially regarding the latter, the video game industry hasn’t been resting on its laurels. Nowadays the polygon count is pumped up the wazoo due to ever-increasing hardware power, and many fancy rendering techniques are applied. One of these rendering techniques reached proper buzzword status in the past few years: ray tracing. It has been a staple of the movie industry for quite a while now, but recently it’s popping up in games as well. But why? What’s so special about ray tracing?Ray tracers are so-called physically based renderers. They aim to model light transport between a virtual camera and light sources in a program. This makes them incredibly intuitive to reason about, as this is exactly what happens in real life! For example, light sources such as the sun or a clip-on GameBoy light emit rays of energy, also known as photons. These photons travel around your surroundings, bouncing against various objects along the way until some of them reach your eyes, resulting in a picture on your retina. Ray tracers mimic these laws of nature, allowing them to produce photo-realistic images.In short, ray tracing is pretty rad. So why not try our hand at making one? In this series I will walk you through the process of writing Manta Ray, my custom ray tracer (yes, I’m proud of that name).IngredientsThis project is going to support physically based rendering with a focus on real-time interactivity. Due to my interest in games I’d like to make Manta Ray pretty fast. Since speed is important to me I opted to use C++; if you’re following along, do note that you can pick whatever programming language you fancy!In time this series will roughly cover the following topics: Ray tracing fundamentals Outputting an image, creating rays and implementing a basic camera Intersections with various primitives Whitted-style ray tracing Acceleration structure construction and traversal Stochastic approaches to anti-aliasing, depth of field, soft shadows, and more Path tracing Variance reduction Filtering techniques Perhaps more as I see fitWithout further ado, let’s get on with it! Don’t get discouraged if these topics do not make much sense at the moment! All of them will be discussed in-depth eventually.Outputting an imageShowing an image is the very first thing a renderer should be able to do. After all, there’s no point in rendering if we can’t see the result! To kickstart the project, I’m using a nice template which provides us with a basic framework for graphics programming in C++. It includes a 32-bit RGB screen buffer to push the rendering results to, some mathematical helper classes and it even comes with OpenCL support if we’d ever fancy a GPU implementation. This way we don’t have to worry about mundane background stuff and get straight to the fun bits!Now then, let’s jot down some C++ code to output a simple image:// the width and height of the screen buffer#define SCRWIDTH 512#define SCRHEIGHT 512// this method is called once per frame while the application is runningvoid mantaray::Tick(float deltaTime){ // clear the previously drawn frame by resetting the screen buffer to black screen-&gt;Clear(0); // loop over all the screen buffer pixels as if reading a book: left-&gt;right, top-&gt;bottom for (int y = 0; y &lt; SCRHEIGHT; y++) for (int x = 0; x &lt; SCRWIDTH; x++) { // calculate some values for the red, green and blue components of a pixel float r = float(x) / (SCRWIDTH - 1); float g = 0.25f; float b = float(y) / (SCRHEIGHT - 1); // convert the calculated values from a [0, 1] range to a [0, 255] RGB range int ir = static_cast&lt;int&gt;(255.0f * r); int ig = static_cast&lt;int&gt;(255.0f * g); int ib = static_cast&lt;int&gt;(255.0f * b); // draw the color to the current screen buffer pixel screen-&gt;Plot(x, y, (ir &lt;&lt; 16) + (ig &lt;&lt; 8) + ib); }}There are some things to note in this code snippet: We loop over each pixel of the screen buffer from left to right, top to bottom. This is by convention; the top-left corner is often defined as the origin when it comes to computer graphics. This might be confusing if you’re used to mathematical grid implementations which usually have the origin sitting at the lower-left corner, so watch out! Another common aspect is to map the red/green/blue component values to a range of 0.0 to 1.0, inclusive. This will later be altered when high dynamic range is implemented.The resulting image should have its red component go from black on the left side of the screen to bright red on the right, while the blue component goes from off at the top to fully on at the bottom. This means that both components should be maxed out in the lower-right corner, resulting in purple. And indeed:Hello Manta Ray! It’s a good idea to “sanity check” your program early and often. This will help prevent frustrating bugs later on.That wraps it up for now! All great things comes from humble beginnings. At least we’re able to render images to the screen buffer, which is an important first step. The next post will (quite literally) introduce a new view as it’ll be about setting up a virtual camera, basic ray casting and vectors. See ya! 🐋" }, { "title": "First Post!", "url": "/posts/first-post/", "categories": "General, Updates", "tags": "introduction", "date": "2022-06-24 11:40:22 +0200", "snippet": "Hi there, welcome to my brand new blog! In the upcoming months (years?) I’ll hopefully be busy adding tons more content to this space. For now, this little introductory post will suffice to kickstart myself into writing at least something.As to not completely copy/paste the About section, let me give you a quick tour instead! New posts will show up in Home. You can further filter entries by browsing the Categories and Tags tabs. I’ll try to keep things neatly organized in this manner.If you’d like to contact me regarding a post, feel free to leave a comment below it! For other inquiries such as information about GitHub repositories, project-related stuff, my favorite pizza toppings or whether I’m able to land a sick kickflip or not (spoiler: definitely not), use any of the social buttons in the sidebar.That’s all for now, see ya around! 👋" } ]
